services:
  cuda:
    build:
      context: .
      dockerfile: ./Dockerfile.cuda
    ports:
      - "8000:8000"
    volumes:
      - ./models:/root/.cache/huggingface/hub:rw
    environment:
      - DEFAULT_MODEL_NAME
      - BATCH_SIZE
      - ACCESS_TOKEN
      - DEFAULT_SCORE
      - USE_API_KEYS
      - API_KEYS
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
